{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c4b72c1-a1f2-44c2-b6ad-c2d4de371176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from langdetect import detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "#Set seed for detector\n",
    "DetectorFactory.seed=0\n",
    "import gensim\n",
    "import nltk\n",
    "from gensim import corpora\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f5cbb37-c2eb-4c3d-8ef5-7e61b6a93e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TSV and convert to CSV\n",
    "tsv_file= 'all_annotated.tsv'\n",
    "csv_table= pd.read_table(tsv_file, sep='\\t')\n",
    "csv_table.to_csv('umass_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32da8650-3f42-464c-8a03-662f57524072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Definitely English</th>\n",
       "      <th>Ambiguous</th>\n",
       "      <th>Definitely Not English</th>\n",
       "      <th>Code-Switched</th>\n",
       "      <th>Ambiguous due to Named Entities</th>\n",
       "      <th>Automatically Generated Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>434215992731136000</td>\n",
       "      <td>TR</td>\n",
       "      <td>2014-02-14</td>\n",
       "      <td>Bugün bulusmami lazimdiii</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>285903159434563584</td>\n",
       "      <td>TR</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>Volkan konak adami tribe sokar yemin ederim :D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>285948076496142336</td>\n",
       "      <td>NL</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>Bed</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>285965965118824448</td>\n",
       "      <td>US</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>I felt my first flash of violence at some fool...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>286057979831275520</td>\n",
       "      <td>US</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>Ladies drink and get in free till 10:30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Tweet ID Country        Date  \\\n",
       "0  434215992731136000      TR  2014-02-14   \n",
       "1  285903159434563584      TR  2013-01-01   \n",
       "2  285948076496142336      NL  2013-01-01   \n",
       "3  285965965118824448      US  2013-01-01   \n",
       "4  286057979831275520      US  2013-01-01   \n",
       "\n",
       "                                               Tweet  Definitely English  \\\n",
       "0                          Bugün bulusmami lazimdiii                   0   \n",
       "1     Volkan konak adami tribe sokar yemin ederim :D                   0   \n",
       "2                                                Bed                   1   \n",
       "3  I felt my first flash of violence at some fool...                   1   \n",
       "4            Ladies drink and get in free till 10:30                   1   \n",
       "\n",
       "   Ambiguous  Definitely Not English  Code-Switched  \\\n",
       "0          0                       1              0   \n",
       "1          0                       1              0   \n",
       "2          0                       0              0   \n",
       "3          0                       0              0   \n",
       "4          0                       0              0   \n",
       "\n",
       "   Ambiguous due to Named Entities  Automatically Generated Tweets  \n",
       "0                                0                               0  \n",
       "1                                0                               0  \n",
       "2                                0                               0  \n",
       "3                                0                               0  \n",
       "4                                0                               0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bring data in\n",
    "df = pd.read_csv(r'umass_tweets.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ab7ab2c-bb66-4d6a-ab47-9842510a4bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10502 entries, 0 to 10501\n",
      "Data columns (total 10 columns):\n",
      " #   Column                           Non-Null Count  Dtype \n",
      "---  ------                           --------------  ----- \n",
      " 0   Tweet ID                         10502 non-null  int64 \n",
      " 1   Country                          10492 non-null  object\n",
      " 2   Date                             10502 non-null  object\n",
      " 3   Tweet                            10502 non-null  object\n",
      " 4   Definitely English               10502 non-null  int64 \n",
      " 5   Ambiguous                        10502 non-null  int64 \n",
      " 6   Definitely Not English           10502 non-null  int64 \n",
      " 7   Code-Switched                    10502 non-null  int64 \n",
      " 8   Ambiguous due to Named Entities  10502 non-null  int64 \n",
      " 9   Automatically Generated Tweets   10502 non-null  int64 \n",
      "dtypes: int64(7), object(3)\n",
      "memory usage: 820.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ede80b9f-77b5-44d7-b2bd-cbc3944c856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean DF up\n",
    "def clean_column_names(df):\n",
    "    # Get the current column names\n",
    "    columns = df.columns.tolist()\n",
    "    # Clean and update the column names\n",
    "    new_columns = []\n",
    "    for column in columns:\n",
    "        # Convert to lowercase\n",
    "        column = column.lower() \n",
    "        # Replace spaces with underscores to make snake case\n",
    "        column = column.replace(' ', '_') \n",
    "        new_columns.append(column)\n",
    "    # Rename the columns in the DataFrame\n",
    "    df.columns = new_columns\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "345fbed3-32ec-4f5a-8a64-83cb2af53ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_column_names(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e37b6756-fbee-4e63-b913-405c94954789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>definitely_english</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>definitely_not_english</th>\n",
       "      <th>code-switched</th>\n",
       "      <th>ambiguous_due_to_named_entities</th>\n",
       "      <th>automatically_generated_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>434215992731136000</td>\n",
       "      <td>TR</td>\n",
       "      <td>2014-02-14</td>\n",
       "      <td>Bugün bulusmami lazimdiii</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>285903159434563584</td>\n",
       "      <td>TR</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>Volkan konak adami tribe sokar yemin ederim :D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>285948076496142336</td>\n",
       "      <td>NL</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>Bed</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>285965965118824448</td>\n",
       "      <td>US</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>I felt my first flash of violence at some fool...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>286057979831275520</td>\n",
       "      <td>US</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>Ladies drink and get in free till 10:30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id country        date  \\\n",
       "0  434215992731136000      TR  2014-02-14   \n",
       "1  285903159434563584      TR  2013-01-01   \n",
       "2  285948076496142336      NL  2013-01-01   \n",
       "3  285965965118824448      US  2013-01-01   \n",
       "4  286057979831275520      US  2013-01-01   \n",
       "\n",
       "                                               tweet  definitely_english  \\\n",
       "0                          Bugün bulusmami lazimdiii                   0   \n",
       "1     Volkan konak adami tribe sokar yemin ederim :D                   0   \n",
       "2                                                Bed                   1   \n",
       "3  I felt my first flash of violence at some fool...                   1   \n",
       "4            Ladies drink and get in free till 10:30                   1   \n",
       "\n",
       "   ambiguous  definitely_not_english  code-switched  \\\n",
       "0          0                       1              0   \n",
       "1          0                       1              0   \n",
       "2          0                       0              0   \n",
       "3          0                       0              0   \n",
       "4          0                       0              0   \n",
       "\n",
       "   ambiguous_due_to_named_entities  automatically_generated_tweets  \n",
       "0                                0                               0  \n",
       "1                                0                               0  \n",
       "2                                0                               0  \n",
       "3                                0                               0  \n",
       "4                                0                               0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d51baa34-6f12-427a-a6d1-349b1a4e8a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect language\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except LangDetectException:\n",
    "        # In case the language can't be detected, return 'unknown'\n",
    "        return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "534cff18-458d-411f-a889-31d14662cb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['language'] = df['tweet'].apply(detect_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aba19c9b-0941-45c5-852f-df8ddd80175e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.language.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e430a21-e699-474e-94e4-1105386465c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "en         4131\n",
       "id         1070\n",
       "es          897\n",
       "pt          880\n",
       "tr          510\n",
       "ja          338\n",
       "tl          277\n",
       "fr          260\n",
       "it          197\n",
       "so          175\n",
       "ca          146\n",
       "ru          145\n",
       "de          144\n",
       "nl          123\n",
       "th          113\n",
       "ar          112\n",
       "et          112\n",
       "af          111\n",
       "fi           75\n",
       "sv           63\n",
       "ro           56\n",
       "sw           56\n",
       "sl           55\n",
       "no           54\n",
       "cy           51\n",
       "da           49\n",
       "ko           38\n",
       "unknown      33\n",
       "pl           32\n",
       "hr           32\n",
       "sq           21\n",
       "hu           21\n",
       "vi           21\n",
       "bg           20\n",
       "lt           20\n",
       "lv           14\n",
       "sk           10\n",
       "cs            9\n",
       "mk            8\n",
       "fa            6\n",
       "uk            5\n",
       "zh-cn         3\n",
       "el            2\n",
       "ta            2\n",
       "he            2\n",
       "hi            2\n",
       "zh-tw         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d013376a-dd99-4337-9cc8-d17621423f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10502 entries, 0 to 10501\n",
      "Data columns (total 11 columns):\n",
      " #   Column                           Non-Null Count  Dtype \n",
      "---  ------                           --------------  ----- \n",
      " 0   tweet_id                         10502 non-null  int64 \n",
      " 1   country                          10492 non-null  object\n",
      " 2   date                             10502 non-null  object\n",
      " 3   tweet                            10502 non-null  object\n",
      " 4   definitely_english               10502 non-null  int64 \n",
      " 5   ambiguous                        10502 non-null  int64 \n",
      " 6   definitely_not_english           10502 non-null  int64 \n",
      " 7   code-switched                    10502 non-null  int64 \n",
      " 8   ambiguous_due_to_named_entities  10502 non-null  int64 \n",
      " 9   automatically_generated_tweets   10502 non-null  int64 \n",
      " 10  language                         10502 non-null  object\n",
      "dtypes: int64(7), object(4)\n",
      "memory usage: 902.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164a045a-b37c-470d-bfca-505e96d48370",
   "metadata": {},
   "source": [
    "# Segmenting data into separate DFs by language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d80522-fdc2-485a-b02c-a99edfcab69e",
   "metadata": {},
   "source": [
    "## English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3782214-7556-484f-9de9-34597ba747d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en = df[df['language'] == 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffc47393-9b6c-494d-af18-0f72c7b45930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized\n",
    "\n",
    "doc_clean = [clean(doc).split() for doc in df_en['tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5431dff1-d33d-436c-b42a-0f1b321eccab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepping document term matrix\n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "988b49d8-a794-403e-a40e-e43ca49bd7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running LDA\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=5, id2word=dictionary, passes=50)  # adjust num_topics and passes based on your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0a200a6-9ac6-434f-9f5d-c58ad36b8b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.010*\"im\" + 0.008*\"gt\" + 0.006*\"big\" + 0.005*\"de\" + 0.005*\"day\"'), (1, '0.016*\"im\" + 0.008*\"like\" + 0.007*\"go\" + 0.006*\"get\" + 0.006*\"back\"'), (2, '0.015*\"—\" + 0.010*\"fit\" + 0.009*\"photo\" + 0.009*\"anyone\" + 0.009*\"hiring\"'), (3, '0.050*\"job\" + 0.033*\"hiring\" + 0.015*\"careerarc\" + 0.014*\"latest\" + 0.011*\"were\"'), (4, '0.009*\"great\" + 0.009*\"here\" + 0.007*\"you\" + 0.007*\"day\" + 0.006*\"im\"')]\n"
     ]
    }
   ],
   "source": [
    "# View the topics\n",
    "print(ldamodel.print_topics(num_topics=5, num_words=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "686e133b-c39b-4b30-9ec9-bd4edead53a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will give you a list of topic distributions for each tweet\n",
    "topic_dist_list = [ldamodel.get_document_topics(item) for item in doc_term_matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "574db45b-0265-44be-9c01-09171b3d3920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Most Probable Topic\n",
    "def get_dominant_topic(topic_list):\n",
    "    # Sorts the topics based on the probabilities, then picks the highest one\n",
    "    return sorted(topic_list, key=lambda x: x[1], reverse=True)[0][0]\n",
    "\n",
    "dominant_topics = [get_dominant_topic(topic_dist) for topic_dist in topic_dist_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a488d57f-4618-44e4-9699-907ff7e839f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to dataframe\n",
    "df_en.loc[:, 'dominant_topic'] = dominant_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f1b903d-ad72-4b16-8f7b-7ffe355f7efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>definitely_english</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>definitely_not_english</th>\n",
       "      <th>code-switched</th>\n",
       "      <th>ambiguous_due_to_named_entities</th>\n",
       "      <th>automatically_generated_tweets</th>\n",
       "      <th>language</th>\n",
       "      <th>dominant_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>285965965118824448</td>\n",
       "      <td>US</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>I felt my first flash of violence at some fool...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>286216100784521216</td>\n",
       "      <td>GB</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>Watching #Miranda On bbc1!!! @mermhart u r HIL...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>286525170670243840</td>\n",
       "      <td>US</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>@Dennycrowe all over twitter because you and y...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>286916662836490241</td>\n",
       "      <td>US</td>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>~ i'm falling apart,with a broken heart,barely...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>286927433498759168</td>\n",
       "      <td>US</td>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>The way you treat me. The way you accept me, a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id country        date  \\\n",
       "3   285965965118824448      US  2013-01-01   \n",
       "7   286216100784521216      GB  2013-01-01   \n",
       "16  286525170670243840      US  2013-01-02   \n",
       "19  286916662836490241      US  2013-01-03   \n",
       "21  286927433498759168      US  2013-01-03   \n",
       "\n",
       "                                                tweet  definitely_english  \\\n",
       "3   I felt my first flash of violence at some fool...                   1   \n",
       "7   Watching #Miranda On bbc1!!! @mermhart u r HIL...                   1   \n",
       "16  @Dennycrowe all over twitter because you and y...                   1   \n",
       "19  ~ i'm falling apart,with a broken heart,barely...                   1   \n",
       "21  The way you treat me. The way you accept me, a...                   1   \n",
       "\n",
       "    ambiguous  definitely_not_english  code-switched  \\\n",
       "3           0                       0              0   \n",
       "7           0                       0              0   \n",
       "16          0                       0              0   \n",
       "19          0                       0              0   \n",
       "21          0                       0              0   \n",
       "\n",
       "    ambiguous_due_to_named_entities  automatically_generated_tweets language  \\\n",
       "3                                 0                               0       en   \n",
       "7                                 0                               0       en   \n",
       "16                                0                               0       en   \n",
       "19                                0                               0       en   \n",
       "21                                0                               0       en   \n",
       "\n",
       "    dominant_topic  \n",
       "3                1  \n",
       "7                0  \n",
       "16               0  \n",
       "19               0  \n",
       "21               1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "15da298a-8cb7-4644-ae43-8f09ac5ff55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create topics list dictionary and append with the calculated topics\n",
    "topics_dict = {}\n",
    "topics_dict['en'] = ldamodel.print_topics(num_topics=5, num_words=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefb933f-5615-4b05-9633-c9015c4137b8",
   "metadata": {},
   "source": [
    "## Indonesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "447df0d6-9313-477e-8ac5-f9f94c947711",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id = df[df['language'] == 'id'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f4f02a7-bd05-4a3d-8be4-4d32e8474a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ecd4cc9-29a4-4430-a85c-24539b38badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "stop = set(stopwords.words('indonesian'))\n",
    "exclude = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "608ad5f7-2b92-4424-a3fa-9b4b9b2c48e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "sklearn.metrics._dist_metrics.DistanceMetric size changed, may indicate binary incompatibility. Expected 472 from C header, got 16 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Using NLP ID indonesian lemmatizer\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnlp_id\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlemmatizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Lemmatizer \n",
      "File \u001b[0;32m~/Documents/Data Science Stuff/virtual_environments/machine_learning/lib/python3.9/site-packages/nlp_id/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnlp_id\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlemmatizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Lemmatizer\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnlp_id\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tokenizer\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnlp_id\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m postag\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnlp_id\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tokenizer, PhraseTokenizer\n",
      "File \u001b[0;32m~/Documents/Data Science Stuff/virtual_environments/machine_learning/lib/python3.9/site-packages/nlp_id/tokenizer.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnlp_id\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Lemmatizer, postag\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTokenizer\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "File \u001b[0;32m~/Documents/Data Science Stuff/virtual_environments/machine_learning/lib/python3.9/site-packages/nlp_id/postag.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnlp_id\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tokenizer\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tree\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DictVectorizer\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n",
      "File \u001b[0;32m~/Documents/Data Science Stuff/virtual_environments/machine_learning/lib/python3.9/site-packages/sklearn/ensemble/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`sklearn.ensemble` module includes ensemble-based methods for\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mclassification, regression and anomaly detection.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseEnsemble\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_forest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_forest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n",
      "File \u001b[0;32m~/Documents/Data Science Stuff/virtual_environments/machine_learning/lib/python3.9/site-packages/sklearn/ensemble/_base.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseEstimator\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MetaEstimatorMixin\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     19\u001b[0m     DecisionTreeRegressor,\n\u001b[1;32m     20\u001b[0m     BaseDecisionTree,\n\u001b[1;32m     21\u001b[0m     DecisionTreeClassifier,\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bunch, _print_elapsed_time, deprecated\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_random_state\n",
      "File \u001b[0;32m~/Documents/Data Science Stuff/virtual_environments/machine_learning/lib/python3.9/site-packages/sklearn/tree/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`sklearn.tree` module includes decision tree-based models for\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mclassification and regression.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_classes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseDecisionTree\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_classes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeClassifier\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_classes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeRegressor\n",
      "File \u001b[0;32m~/Documents/Data Science Stuff/virtual_environments/machine_learning/lib/python3.9/site-packages/sklearn/tree/_classes.py:42\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_is_fitted\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Hidden, Interval, StrOptions\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_criterion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Criterion\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_splitter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Splitter\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DepthFirstTreeBuilder\n",
      "File \u001b[0;32msklearn/tree/_criterion.pyx:1\u001b[0m, in \u001b[0;36minit sklearn.tree._criterion\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msklearn/tree/_splitter.pyx:1\u001b[0m, in \u001b[0;36minit sklearn.tree._splitter\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msklearn/tree/_tree.pyx:1\u001b[0m, in \u001b[0;36minit sklearn.tree._tree\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/Data Science Stuff/virtual_environments/machine_learning/lib/python3.9/site-packages/sklearn/neighbors/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`sklearn.neighbors` module implements the k-nearest neighbors\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03malgorithm.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ball_tree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BallTree\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_kd_tree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KDTree\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_distance_metric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistanceMetric\n",
      "File \u001b[0;32msklearn/neighbors/_ball_tree.pyx:1\u001b[0m, in \u001b[0;36minit sklearn.neighbors._ball_tree\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: sklearn.metrics._dist_metrics.DistanceMetric size changed, may indicate binary incompatibility. Expected 472 from C header, got 16 from PyObject"
     ]
    }
   ],
   "source": [
    "#Using NLP ID indonesian lemmatizer\n",
    "from nlp_id.lemmatizer import Lemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541741dc-f926-4e7c-9838-b1d5858b07a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
